{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45b8862-0071-4e18-a63f-f475f65cbf61",
   "metadata": {},
   "source": [
    "# Function Calling in LLM Models\n",
    "\n",
    "## Introduction\n",
    "LLM models excel at various NLP tasks such as:\n",
    "\n",
    "- **Question & Answering (Q&A)**\n",
    "- **Pattern-based problem-solving**\n",
    "- **Language translation**\n",
    "- **Other NLP-related capabilities**\n",
    "\n",
    "With the right **prompt engineering techniques**, many companies have replaced some of their traditional NLP-based solutions. These conventional solutions typically involve:\n",
    "\n",
    "- **Data collection** 📊\n",
    "- **Data processing** 🔄\n",
    "- **Model training & testing** 🏋️‍♂️\n",
    "\n",
    "Such tasks often require **a skilled data scientist**, making the process resource-intensive.\n",
    "\n",
    "## Why Function Calling?\n",
    "The core idea behind **Function Calling** is:\n",
    "\n",
    "- 🤔 What if we want an LLM model to perform a specific task **in a customized way**, beyond its training?\n",
    "- 🤖 What if we need the model to complete a task **it wasn't explicitly trained for**?\n",
    "- ⏳ What if the context provided to the LLM is **real-time and dynamic**?\n",
    "\n",
    "This is where **Function Calling** plays a crucial role! It extends the capabilities of LLMs by enabling them to:\n",
    "\n",
    "- Interact with external systems 📡\n",
    "- Process dynamic inputs 📥\n",
    "- Retrieve real-time data ⏳\n",
    "- Execute specific functions 🛠️\n",
    "\n",
    "## Exploring Function Calling\n",
    "Now that we understand the purpose, let's explore **Function Calling** in more detail!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b46d12-4b7d-4f78-95a9-e2cc555207a5",
   "metadata": {},
   "source": [
    "# Function vs Tool in Python and LLMs\n",
    "\n",
    "- In **Python**, we refer to it as a **function**.\n",
    "- In **LLM terminology**, the same thing is called a **tool**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30877ac8-eea0-409f-a282-28f1e335e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create a simple function\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from typing import Optional\n",
    "\n",
    "@tool\n",
    "def greet(name:str,role:Optional[str]=None)-> str: # i don't know where below company exists. please don't get offended. This is strictly for educational purpose\n",
    "    \"\"\"\n",
    "    this function will take a name and will greet them in the ways of WiseTechGaint companies culture\n",
    "\n",
    "    Args:\n",
    "        name (str): name of the employee in WiseTechGaint\n",
    "        role (str,optional): role of the employee in WiseTechGaint. Defaults to None\n",
    "\n",
    "    Returns:\n",
    "        str: greeting message to the person\n",
    "\n",
    "    Examples:\n",
    "        >>> greet(\"sweet\")\n",
    "        Hello sweet, we are proud to invite you to WiseTechGaint. From today you are part of WSTians.\n",
    "\n",
    "        >>> greet(\"chole\",\"software developer\")\n",
    "        Hello Chole, we are pround to invite you to WiseTechGaint. Good Luck with your software developer role. From today you are part of WSTians\n",
    "    \"\"\"\n",
    "\n",
    "    if role:\n",
    "        return f\"Hello {name}, we are pround to invite you to WiseTechGaint. Good Luck with your {role} role. From today you are part of WSTians\"\n",
    "    return f\"Hello {name}, we are proud to invite you to WiseTechGaint. From today you are part of WSTians.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93c562d-8987-4440-9b3a-3290bc08d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # if have .env file which have groq API key as environment variable\n",
    "\n",
    "tools = [greet] # we will all our tools here\n",
    "llm = init_chat_model(\"deepseek-r1-distill-llama-70b\",model_provider=\"groq\")\n",
    "llm_with_tools = llm.bind_tools(tools) # bind your tools here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c419025-3369-42ef-8377-ffbdaa608218",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resp = llm_with_tools.invoke(\"what is the result of 2 multiplied with 100\") # when i have asked this math question, LLM understood that it need not call the greet function that i have created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bedc0fd3-00f9-467a-8a49-a4e5d80f6e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of multiplying 2 by 100 is 200.\\n\\nStep-by-Step Explanation:\\n1. **Understand the Problem**: We need to calculate 2 multiplied by 100.\\n2. **Multiplication as Repeated Addition**: Multiplying 2 by 100 is the same as adding 100 two times: 100 + 100.\\n3. **Perform the Addition**: Adding 100 and 100 gives 200.\\n4. **Verification**: Another way to think about it is that multiplying by 100 adds two zeros to the number, turning 2 into 200.\\n5. **Conclusion**: Therefore, 2 × 100 equals 200.\\n\\nAnswer: 200'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65daf972-c666-442d-aa29-c0495ad32f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resp.tool_calls # you can see the tool call is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbeaf9f8-a1a9-4ffa-afb8-637af66b5602",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resp = llm_with_tools.invoke(\"a new employee named andrew joined our company as a technical associate. kindly greet him.\") # let's observe now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "706f24a6-47a2-40d4-a905-045baf7c43c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resp.content # now you can observe LLM model did not response with a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abc50e11-6084-43e4-b5ed-fd0742dfd034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'greet',\n",
       "  'args': {'name': 'andrew', 'role': 'technical associate'},\n",
       "  'id': 'call_2tcq',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_resp.tool_calls # instead LLM understood the context and retuns the function that has to be called along with function arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ce6047-d22b-4775-8d21-9113b95d1b9f",
   "metadata": {},
   "source": [
    "LLM models can't run the function by itself (**Langgraph solved this problem differently. We will explore this later in Agents Concepts**). But, it can return the function that we need to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52107e7d-cc48-4f11-ad96-20b17c314e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model resp:  Hello andrew, we are pround to invite you to WiseTechGaint. Good Luck with your technical associate role. From today you are part of WSTians\n"
     ]
    }
   ],
   "source": [
    "for each_tool in model_resp.tool_calls:\n",
    "    function_call = eval(each_tool[\"name\"])\n",
    "    print(\"model resp: \",function_call.invoke(each_tool[\"args\"])) # we can only invoke the tool this way. not like normal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bab824f-e929-4ce5-93d0-e26b1b90172b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ec2e3f7-f7f3-4956-8740-2425486e5fa8",
   "metadata": {},
   "source": [
    "### Now Let's Learn Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "493d9ca6-a8bc-4f6f-b2b0-e9ef25447d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_analysis_response = llm.invoke(\"\"\"\n",
    "Hi my name is Nichole, i am currently working in ABC tech company in Vadodara. I have been working in this place for mrore than \n",
    "5 years. This place is nice but my family is in London. Since we have an office in London, i am requesting you to pack and ship me\n",
    "over there permenantly. i will continue to work productively as if i am right now. thank you\n",
    "\n",
    "---\n",
    "Task: Find names, locations, company_names in above sentence. Also, give a short 15 words summary of the above sentence. Also, provide sentiment of the sentence\n",
    "\n",
    "Note: i only need JSON response. I dont want your explanation\n",
    "Sample Response : {\"names\":[],\"locations\":[],\"company_names\":[],\"summary\":\"\",\"sentiment\":\"\"}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "349b4c39-41ef-4044-8b4a-b62b9f52eb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, I need to help the user extract specific information from their query. They provided a sentence and want me to find names, locations, and company names. Let me read through the sentence carefully.\\n\\nFirst, looking for names. I see \"Nichole\" mentioned at the beginning. That\\'s a name. I don\\'t see any other names in the sentence.\\n\\nNext, locations. There are two places mentioned: \"Vadodara\" and \"London.\" Both are cities, so those are the locations.\\n\\nFor company names, the sentence says \"ABC tech company.\" So that\\'s the company name. I should include that.\\n\\nNow, the summary needs to be 15 words. The main points are Nichole working in Vadodara for ABC Tech, wanting to move to London because her family is there, and the office exists there. I\\'ll condense that into a concise sentence.\\n\\nLastly, the sentiment. The overall tone is positive because she\\'s expressing gratitude and willingness to continue working productively. So the sentiment is positive.\\n\\nI should structure all this into a JSON response as per the sample provided. Making sure each category is correctly filled and the summary is within the word limit. No extra explanations, just the JSON.\\n</think>\\n\\n```json\\n{\\n  \"names\": [\"Nichole\"],\\n  \"locations\": [\"Vadodara\", \"London\"],\\n  \"company_names\": [\"ABC tech company\"],\\n  \"summary\": \"Nichole, working at ABC Tech in Vadodara, requests a permanent transfer to London to join her family.\",\\n  \"sentiment\": \"positive\"\\n}\\n```'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_analysis_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43902fe5-fced-47e3-9231-f0e2bac00f2d",
   "metadata": {},
   "source": [
    "We got the output correctly in json, but we still need to write some logic to get JSON correctly.\n",
    "\n",
    "\n",
    "Now Let's See how **Structured Output** Solves this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ccdd8e2b-040e-4b28-b3fa-40ceb4f5ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel,Field\n",
    "from typing import List, Literal,Union,Any\n",
    "\n",
    "class text_result(BaseModel):\n",
    "    \"\"\"\n",
    "    For NLP Tasks related to extracting entities, intent, summary and sentiment\n",
    "    \"\"\"\n",
    "    names:List[str] = Field(...,description=\"List of person names\")\n",
    "    locations:List[str] = Field(...,description=\"List of geographical locations\")\n",
    "    company_names:List[str] = Field(...,description=\"List of any type of company name\")\n",
    "    summary:str = Field(...,description=\"summary of the conversation/text\")\n",
    "    sentiment:Literal[\"positive\",\"negative\",\"neutral\"] = Field(...,description=\"sentiment of the conversation/text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d675a5-4c76-45bd-bd9a-f8cbd0486422",
   "metadata": {},
   "source": [
    "It is not a compulsion that we have to use Pydantic\n",
    "\n",
    "\n",
    "We can use normal `json schema` or standard `typing` module too. But `Pydantic` makes sure the data types are strictly followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b03ce0b8-139f-4c9b-8594-585914955de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(text_result)\n",
    "structured_resp = structured_llm.invoke(\"\"\"\n",
    "Hi my name is Nichole, i am currently working in ABC tech company in Vadodara. I have been working in this place for mrore than \n",
    "5 years. This place is nice but my family is in London. Since we have an office in London, i am requesting you to pack and ship me\n",
    "over there permenantly. i will continue to work productively as if i am right now. thank you\n",
    "\n",
    "---\n",
    "Task: Find names, locations, company_names in above sentence. Also, give a short 15 words summary of the above sentence. Also, provide sentiment of the sentence\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55c14562-2020-4e8f-8afa-cfbd686815e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_result(names=['Nichole'], locations=['Vadodara', 'London'], company_names=['ABC Tech'], summary='Nichole requests a transfer to London from Vadodara for family reasons.', sentiment='neutral')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_resp # This is the beauty of structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b55ea9d9-c95a-4093-85a6-2822a0a90290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nichole']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_resp.names # we can directly access extracted fields without any post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9af55-ff10-4614-8f05-185b592b24f4",
   "metadata": {},
   "source": [
    "#### What if you want structured output for a specific query and for the rest, respond normally ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb6fbca2-ffeb-4a77-a7a7-624b798c7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    For conversations other than NLP related tasks\n",
    "    \"\"\"\n",
    "    response:str\n",
    "\n",
    "class LLMResponse(BaseModel):\n",
    "    modelresp: Union[text_result,DefaultResponse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "238ef9a4-477e-4c50-9fb5-ea49c7058a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_structured_llm = llm.with_structured_output(LLMResponse,include_raw=False) # we can also preserve llmresponse using include_raw=True\n",
    "\n",
    "structured_resp = complex_structured_llm.invoke(\"\"\"\n",
    "Hi my name is Nichole, i am currently working in ABC tech company in Vadodara. I have been working in this place for mrore than \n",
    "5 years. This place is nice but my family is in London. Since we have an office in London, i am requesting you to pack and ship me\n",
    "over there permenantly. i will continue to work productively as if i am right now. thank you\n",
    "\n",
    "---\n",
    "Task: Find names, locations, company_names in above sentence. Also, give a short 15 words summary of the above sentence. Also, provide sentiment of the sentence\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8e388602-34f9-4686-9507-9e9183542750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_result(names=['Nichole'], locations=['Vadodara', 'London'], company_names=['ABC Tech'], summary='Nichole requests transfer to London to be closer to family while continuing productive work.', sentiment='positive')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_resp.modelresp # see we got a structured output for above query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "245357eb-b8d5-4db9-b1ed-95aa3eded8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_resp = complex_structured_llm.invoke(\"what is the result if 5 is multiplied with 123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "70a2f1a9-90ca-44f0-9946-010318669f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultResponse(response='The result of multiplying 5 by 123 is 615.')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_resp.modelresp # As you can see here, for other queries the response structure is different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb77210-26cf-407d-a7e0-071082a9981f",
   "metadata": {},
   "source": [
    "`Note`: We can't use a single **LLM instance** to perform both **function calling** and **StructuredOutput**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4e84e-9523-4750-8c93-05b570f5ed4c",
   "metadata": {},
   "source": [
    "# 🚀 A Quick Recap on What We Have Learned So Far\n",
    "\n",
    "## 📌 Key Takeaways\n",
    "\n",
    "1. **Using Python Functions as Tools for LLM Models**  \n",
    "   - We learned how to pass Python functions as tools to LLM models.  \n",
    "   - We can add multiple tools, but adding **30 or more** can be overwhelming. ⚠️ Too many tools might confuse the model.\n",
    "\n",
    "2. **Structuring LLM Responses**  \n",
    "   - We can structure LLM responses in a desired format using:\n",
    "     - `pydantic` (✅ Preferred method)\n",
    "     - JSON Schema\n",
    "     - Standard `typing` library\n",
    "   - If multiple structured response models are needed, we can use a **single parent Pydantic model**.\n",
    "   - The `Union` feature in the `typing` library helps include multiple models efficiently.\n",
    "\n",
    "3. **Tool Calls vs. Structured Responses**  \n",
    "   - ❌ We **cannot** use both **tool calls** and **structured output responses** simultaneously for a **single LLM model instance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b8c64-d3d1-4020-a1e9-1569d1b1dd63",
   "metadata": {},
   "source": [
    "# ⚡ Model Response Caching\n",
    "\n",
    "## 🤔 Why Do We Need This?\n",
    "- If you are using an LLM model hosted on **OpenAI, Cohere, or GroqAI**, you are **paying** for each input and output token processed per request. 💰\n",
    "- By default, even if a question has been answered before, the LLM still processes it again, **costing you unnecessarily**.\n",
    "- **Solution:** Caching model results helps **save costs** and **improves response times**. ⚡\n",
    "\n",
    "## 📍 Where Is This Cache Stored?\n",
    "1. **In-Memory Caching** (🚀 Fast but temporary)\n",
    "   - Limited by process lifecycle—cache **disappears** when the process restarts.\n",
    "\n",
    "2. **Database-Based Caching** (✅ Persistent & Reliable)\n",
    "   - Stores cache **across runtime restarts**.\n",
    "   - Popular options include:\n",
    "     - **SQLite** (Local file-based persistence 🗂️)\n",
    "     - **Redis Cache** (Local & cloud-based database solution 🌍)\n",
    "     - **AstraDB Cache** (Cloud-based database solution ☁️)\n",
    "   - ...and many more!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aeab1f-a750-4778-9b18-397abd00061b",
   "metadata": {},
   "source": [
    "### Redis Cloud Storage Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70689d24-b0c2-454e-a763-6f450706e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have created a free redis server for demo purpose. I am not an idiot i will delete this server by the time you see this.\n",
    "\n",
    "import redis\n",
    "\n",
    "redis_config = redis.Redis(\n",
    "    host='redis-13626.c266.us-east-1-3.ec2.redns.redis-cloud.com',\n",
    "    port=13626,\n",
    "    decode_responses=True,\n",
    "    username=\"default\",\n",
    "    password=\"UdKYui6jv3Bf7LiRr222fmeRMmo96Pll\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4739b22d-c859-46a8-9ab0-155a8cd86714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache ## use this for in memory cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd9fb657-551d-476d-bf46-97d834b4afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(RedisCache(redis_=redis_config)) # I have set Redis Cloud Server for cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c728b6c3-429a-4f43-a758-ae73a98560ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = llm.invoke(\"tell me about Agents in 25 words\") # you can see the response time for first hit is 2 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df9943dc-c785-489f-8d11-8239a7ea2bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to explain what agents are in 25 words. Let me think about what an agent is. From what I remember, in computing, an agent is like a program that does tasks on your behalf. They can be autonomous, meaning they work on their own without much interference. They might have different roles, like a user agent in a web browser or a software agent handling specific tasks.\\n\\nI think agents can be smart, using AI to make decisions or learn. They might interact with environments, like in robotics or chatbots. Also, there are different types, such as intelligent agents that adapt and learn. So, putting this together, I should mention that agents are autonomous, can be AI-driven, operate in various environments, and handle tasks like information retrieval or decision-making.\\n\\nLet me count the words to make sure it's around 25. I'll try to be concise and cover the key points: autonomy, AI, environments, tasks, adaptability, learning, and examples like chatbots and robots.\\n\\nHmm, I think I have a good structure. Let me piece it together.\\n</think>\\n\\nAgents are autonomous, AI-driven entities that operate in various environments, performing tasks like information retrieval or decision-making, often adapting and learning, as seen in chatbots and robots.\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e0ec8461-9957-4c03-848c-80a7a50286f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 349 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = llm.invoke(\"tell me about Agents in 25 words\") # same question, now it took 389ms. proof of caching in case you didn't believe me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e6ad1-6a5d-4d9f-90fa-4ecc7743510f",
   "metadata": {},
   "source": [
    "You can see data is inserted to redis server\n",
    "\n",
    "![Redis Server Cache](redis_cache.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181155ce-e4af-459e-bf03-678eeff2be5e",
   "metadata": {},
   "source": [
    "### InMemory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "703b97aa-4402-4990-875b-9f9da8438f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d223c2e2-2fd4-4d05-9fc8-4a271fc467b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = llm.invoke(\"tell me about Agents in 25 words\") # Since, we changed cache to InMemory, it again took 2.9 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba379210-19cc-49e2-aed4-f56fa1ca8777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out what an agent is, and then describe it in 25 words. Hmm, where do I start? I\\'ve heard the term \"agent\" used in different contexts, so maybe I should break it down.\\n\\nFirst, in computing, I think an agent is like a program that does tasks automatically. Like, maybe a software agent that helps with something. I remember hearing about chatbots being a type of agent. They interact with users, answer questions, maybe even help with customer service. So, that\\'s one aspect.\\n\\nThen there\\'s the idea of agents in a more general sense. I think in AI, an intelligent agent is something that perceives its environment and takes actions to achieve goals. That makes sense. So, an agent could be a program or a system that operates with some degree of autonomy.\\n\\nWait, autonomy is a key point here. Agents don\\'t just follow explicit instructions every time; they can make decisions based on their environment. But how exactly do they do that? I guess they use some kind of programming or algorithms to decide what actions to take.\\n\\nIn multi-agent systems, there are multiple agents that interact with each other. They could be cooperative or competitive. For example, in economics, agents might represent different actors like consumers and producers making decisions in a market.\\n\\nAlso, in cybersecurity, I\\'ve heard about agents being software that runs on a computer to manage it or protect it. Like, an agent that monitors for malware or manages updates. So, in that context, the agent is a tool that acts on behalf of the system administrator.\\n\\nAnother angle is in the context of AI, where an agent might have different types, like reactive agents that respond to the present situation without reasoning, or cognitive agents that can plan and reason. So, the complexity of the agent can vary widely.\\n\\nI should also consider the definition. What\\'s the core of an agent? It seems to be an entity that acts on behalf of another entity, whether it\\'s a person, a system, or another agent. So, the key is the action and the autonomy in decision-making.\\n\\nPutting this together, an agent is an entity that acts autonomously to achieve goals, using its environment and possibly interacting with other agents. They can be simple or complex, depending on their programming and the tasks they perform.\\n\\nNow, to describe this in 25 words: An agent is an autonomous entity that perceives its environment and takes actions to achieve specific goals, often operating independently or in coordination with other agents.\\n</think>\\n\\nAn agent is an autonomous entity that perceives its environment and takes actions to achieve specific goals, often operating independently or in coordination with others.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content # You can also observe content is different here. because LLM wont give same response for same query if caching is not implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c58d1ef-0485-403c-ba1a-22e608ed70c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resp = llm.invoke(\"tell me about Agents in 25 words\") # this is even faster 1.12 ms because this is in-memory where as, previously we used a cloud Redis DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "262b0cc7-0cc8-4a64-9830-98475c82eaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out what an agent is, and then describe it in 25 words. Hmm, where do I start? I\\'ve heard the term \"agent\" used in different contexts, so maybe I should break it down.\\n\\nFirst, in computing, I think an agent is like a program that does tasks automatically. Like, maybe a software agent that helps with something. I remember hearing about chatbots being a type of agent. They interact with users, answer questions, maybe even help with customer service. So, that\\'s one aspect.\\n\\nThen there\\'s the idea of agents in a more general sense. I think in AI, an intelligent agent is something that perceives its environment and takes actions to achieve goals. That makes sense. So, an agent could be a program or a system that operates with some degree of autonomy.\\n\\nWait, autonomy is a key point here. Agents don\\'t just follow explicit instructions every time; they can make decisions based on their environment. But how exactly do they do that? I guess they use some kind of programming or algorithms to decide what actions to take.\\n\\nIn multi-agent systems, there are multiple agents that interact with each other. They could be cooperative or competitive. For example, in economics, agents might represent different actors like consumers and producers making decisions in a market.\\n\\nAlso, in cybersecurity, I\\'ve heard about agents being software that runs on a computer to manage it or protect it. Like, an agent that monitors for malware or manages updates. So, in that context, the agent is a tool that acts on behalf of the system administrator.\\n\\nAnother angle is in the context of AI, where an agent might have different types, like reactive agents that respond to the present situation without reasoning, or cognitive agents that can plan and reason. So, the complexity of the agent can vary widely.\\n\\nI should also consider the definition. What\\'s the core of an agent? It seems to be an entity that acts on behalf of another entity, whether it\\'s a person, a system, or another agent. So, the key is the action and the autonomy in decision-making.\\n\\nPutting this together, an agent is an entity that acts autonomously to achieve goals, using its environment and possibly interacting with other agents. They can be simple or complex, depending on their programming and the tasks they perform.\\n\\nNow, to describe this in 25 words: An agent is an autonomous entity that perceives its environment and takes actions to achieve specific goals, often operating independently or in coordination with other agents.\\n</think>\\n\\nAn agent is an autonomous entity that perceives its environment and takes actions to achieve specific goals, often operating independently or in coordination with others.'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b9934-6e51-4ed8-b9be-1c7f691be468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
