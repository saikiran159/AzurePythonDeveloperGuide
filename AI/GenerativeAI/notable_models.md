# 🏆 Paid or Cloud API Models

## 1️⃣ Groq AI
- 🚀 We can use models like **LLaMA, DeepSeek, Gemma, and Mistral** for free with some limits.
- ⚡ API response is **very fast**.
- 🎙️ OpenAI **Whisper models** are also hosted here.

## 2️⃣ OpenAI
- 🤖 A model that **needs no introduction**—our **first priority**.
- 💰 **Costly** option.

## 3️⃣ Anthropic
- 🏆 A **good competitor** to OpenAI, our **second priority**.
- 💲 **Cheaper** than OpenAI models.

## 4️⃣ Cohere
- 🧪 We can **experiment** and use this if **price & performance** meet our needs.
- 💰 Price is **almost the same** as Anthropic.

## 5️⃣ Gemma
- 💲 **Much cheaper** than most models mentioned above.
- 🔍 Other **Google's closed models** are available here.

## 6️⃣ Mistral AI
- 🔒 Other **closed Mistral models** are available here.
- 💲 **Cheaper** than Anthropic and Cohere.

---

# 💻 Locally Runnable Models

## 1️⃣ Ollama
- 🏠 We can run **all open-source models locally** (**GPU is preferred**).
- 🛠️ Supports **custom models** (GGUF or safetensors format).
- 🖥️ We can add **UI as a plugin** too.
- 🔗 Once running locally, we can **interact via Python/JS SDKs**.
- 🏎️ Supports both **CPU & GPU**.

## 2️⃣ Nomic GPT4ALL
- 🏢 Similar to Ollama but offers **enterprise support**.

## 3️⃣ LM Studio
- 🏗️ Similar to Ollama but **supports ARM chipsets**.
- 📡 Has **OpenAI-like API specifications** for all models in its catalog.

## 4️⃣ Cortex
- ⚙️ Uses **LLaMA.cpp** as the backend inference API **(for now)**.
- 🔮 Future plans to use **ONNX as the inference engine**.
- 💬 **Jan** is a ChatGPT-like UI built on top of Cortex.

## 5️⃣ LLaMA.cpp ([GitHub](https://github.com/ggerganov/llama.cpp))
- 🚀 **Plain C & C++ engine** for **state-of-the-art performance**.
- 🏎️ **Reduced memory usage** & supports **ARM chips**.
- 🔥 Supports **1.5-bit quantization** for faster inference.
- 🏎️ **Hybrid CPU + GPU inference**.
- 🛠️ SDKs available in **Python, JS, Java, C#, Flutter, Go, etc.**
- 🖥️ Supports **UI plugins** (even for AI code editing!).

## 6️⃣ Local AI
- 🔧 Supports **LLaMA.cpp**.
- 🛠️ Features: **TTS, transcription, image generation, embeddings, store, re-ranker, etc.**

## 7️⃣ Llamafile ([GitHub](https://github.com/Mozilla-Ocho/llamafile))
- 📦 **Higher-level abstraction** over **LLaMA.cpp** for easier deployment.
- ⚡ **Same performance** as LLaMA.cpp but requires **no library installation**.
- 📡 **Supports OpenAI API spec**.
- ⚠️ **Still a bit unstable** at the time of testing—proper testing is recommended before production use!
